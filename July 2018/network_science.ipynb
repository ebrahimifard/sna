{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network\n",
    "Working with NetworkX and Gephi\n",
    "\n",
    "\n",
    "\n",
    "### By Amir E. Fard\n",
    "### aef1370@gmail.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Undirected networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Adding the nodes\n",
    "G.add_node(1)\n",
    "G.add_nodes_from([2,3,4,5])\n",
    "G.add_node(6)\n",
    "G.add_nodes_from([7,8,9,10])\n",
    "G.add_node(11)\n",
    "G.add_node(12)\n",
    "\n",
    "# Adding the edges\n",
    "G.add_edge(1,3)\n",
    "G.add_edge(*(1,5))\n",
    "G.add_edges_from([(2,4), (4,5), (3,4), (10,9), (2,3)])\n",
    "G.add_edges_from([(7,9), (7,8), (8,10), (6,9)])\n",
    "\n",
    "# Visualization\n",
    "# nx.draw(G, with_labels=True)\n",
    "# nx.draw_kamada_kawai(G, with_labels=True)\n",
    "# nx.draw_networkx(G, with_labels=True)\n",
    "# nx.draw_random(G, with_labels=True)\n",
    "# nx.draw_shell(G, with_labels=True)\n",
    "# nx.draw_spectral(G, with_labels=True)\n",
    "nx.draw_spring(G, with_labels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Network with attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node attribute\n",
    "G =nx.Graph()\n",
    "G.add_edges_from([(1,2),(1,3),(2,3),(4,5),(5,6),(7,8),(3,6),(4,8)])\n",
    "# G.nodes is the method to associate an attribute to an existing node \n",
    "for i in G.nodes:\n",
    "    if i%2 == 0:\n",
    "        G.nodes[i][\"colour\"] = \"Red\"\n",
    "    else:\n",
    "        G.nodes[i][\"colour\"] = \"Blue\"\n",
    "    G.nodes[i][\"name\"] = f'Node {i}'\n",
    "\n",
    "G.add_node(9,colour=\"Yellow\")\n",
    "G.nodes.data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edge attribute\n",
    "G =nx.Graph()\n",
    "G.add_edges_from([(u,random.randint(1,11),{\"weight\": random.uniform(1,10), \"colour\":random.choice([\"Red\", \"Blue\"])}) for u in  range(1,10)])\n",
    "G.edges.data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization based on attributes\n",
    "# Here, we added size & colour to the nodes and weight to the edges\n",
    "G = nx.generators.random_graphs.fast_gnp_random_graph(10,0.25)\n",
    "edgeWeights = [random.randint(1,5) for i in range(10)]\n",
    "nodeSize = [random.randint(1,1000) for i in range(10)]\n",
    "nodeColour = [random.choice([\"r\",\"b\", \"green\", \"yellow\"]) for i in range(10)]\n",
    "\n",
    "\n",
    "pos = nx.circular_layout(G)\n",
    "nx.draw_networkx_nodes(G, pos, node_size=nodeSize, node_color=nodeColour)\n",
    "nx.draw_networkx_edges(G, pos, width=edgeWeights)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Directed networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DG = nx.DiGraph()\n",
    "DG.add_edge(1,2)\n",
    "DG.add_edges_from([(1,4),(1,5),(5,3)])\n",
    "DG.add_edge(3,2)\n",
    "DG.add_edges_from([(4,3),(6,2)])\n",
    "DG.add_nodes_from([7,8,9])\n",
    "DG.add_edge(9,7)\n",
    "nx.draw_circular(DG, with_labels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we reviewed three important types of networks (i) undirected, (ii) weighted and (iii) directed networks. Also, we saw how networks with different properties can be visualized. In the next step, we look at some metrics in networks. But before that, as a conclusion to this part (without looking at the answer) try to solve challenge 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GG = nx.erdos_renyi_graph(20, 0.2)\n",
    "nx.draw(GG, pos=nx.circular_layout(GG), with_labels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 1\n",
    "Make a random directed graph with 50 nodes and give a random weight from 1 to 10 to each edge. Then visualize the graph regarding two following conditions:\n",
    "1- The size of the nodes should be associated with the nodes degree\n",
    "2- The thickness of each edge should be associted with edge weights\n",
    "3- The colour of nodes has to be associated with their degree in a way that as the degree of a node increases the colour of that node becomes more sharp\n",
    "3- The colour of edges has to be associated with their weights in a way that as the weight of an edge increases the colour of that edge becomes more sharp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.erdos_renyi_graph(10, 0.1, directed=True)\n",
    "inDeg = dict(G.in_degree())\n",
    "outDeg = dict(G.out_degree())\n",
    "for edge in G.edges:\n",
    "    G[edge[0]][edge[1]][\"weight\"] = random.randint(1,5)\n",
    "edgeWeights = [u[2][\"weight\"] for u in G.edges.data()]\n",
    "\n",
    "# Making the colour palette and linking it the edges according to theor weights\n",
    "colourPalette = sns.color_palette(\"Blues\",5)\n",
    "edgeWeighColour = dict(zip(range(1,6),colourPalette))\n",
    "for edge in G.edges:\n",
    "    G[edge[0]][edge[1]][\"colour\"] = edgeWeighColour[G[edge[0]][edge[1]][\"weight\"]]\n",
    "edgeColours = [u[2][\"colour\"] for u in G.edges.data()]   \n",
    "\n",
    "# Associating the color of the nodes with the their out-degree\n",
    "outDegUnique = np.unique([i for i in outDeg.values()])\n",
    "colourPalette = sns.color_palette(\"Reds\",len(outDegUnique))\n",
    "nodeOutDegDict = dict(zip(outDegUnique,colourPalette))\n",
    "for i in G.nodes:\n",
    "    G.nodes[i][\"colour\"] = nodeOutDegDict[outDeg[i]]\n",
    "nodeColour = [i[1][\"colour\"] for i in G.nodes.data()]\n",
    "    \n",
    "# This line makes the figure bigger\n",
    "plt.figure(num=None, figsize=(12, 10), dpi=80)\n",
    "\n",
    "# Setting the layout, nodes, edges and lables\n",
    "pos = nx.circular_layout(G)\n",
    "nx.draw_networkx_nodes(G, pos, node_size=[(u,100*inDeg[u]) for u in inDeg], node_color=nodeColour)\n",
    "nx.draw_networkx_edges(G, pos, width=edgeWeights, edge_color=edgeColours)\n",
    "nx.draw_networkx_labels(G, pos)\n",
    "\n",
    "# Drawing the network\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Degrees and degree distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since then, in some sections we work with existing networks. So, here we load a couple of different networks to be able to use them during our workshop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the network of fake-news related concepts in wikipedia \n",
    "wikipediaFakeNewsAdr = \"./data/graph_100.gexf\"\n",
    "wikipediaConcepts = nx.read_gexf(wikipediaFakeNewsAdr)\n",
    "nx.draw(wikipediaConcepts, with_labels=True)\n",
    "plt.savefig(\"wiki.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the Zachery Karate Club network\n",
    "zacharyAdr = \".data/ucidata-zachary/out.ucidata-zachary\"\n",
    "zacharyNetworkEdges = [tuple(a.strip().split(\" \")) for a in open(zacharyAdr).readlines()[2:]]\n",
    "G = nx.Graph()\n",
    "G.add_edges_from(zacharyNetworkEdges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Degree distribution\n",
    "degree_sequence = sorted([d for n, d in wikipediaConcepts.degree()], reverse=True)  # degree sequence\n",
    "# print \"Degree sequence\", degree_sequence\n",
    "degreeCount = collections.Counter(degree_sequence)\n",
    "deg, cnt = zip(*degreeCount.items())\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "plt.bar(deg, cnt, width=0.80, color='b')\n",
    "\n",
    "\n",
    "plt.title(\"Degree Histogram\")\n",
    "plt.ylabel(\"Count\" , fontsize=12)\n",
    "plt.xlabel(\"Degree\", fontsize=12)\n",
    "ax.set_xticks([d + 0.4 for d in deg])\n",
    "ax.set_xticklabels(deg)\n",
    "plt.xticks(rotation=90, fontsize=12)\n",
    "\n",
    "plt.savefig(\"hist.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Centrality Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Degree centrality\n",
    "# C(i) ~ k(i) (centrality of node i changes by degree of that node)\n",
    "# Based on degree centrality, the more connection a node has, the more important that node is. Airport, citation and friendship are the cases that degree centrality works well\n",
    "degreeCentrality = nx.degree_centrality(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Closeness centrality\n",
    "# This measure is calculated via C = 1/L(i) which L(i) denotes the average distance of node i to all the others. Collaboration networks is a case that closeness centrality works well \n",
    "# Closeness centrality doesn't span much\n",
    "# Check Erdos-number and Bacon-number\n",
    "closenessCentrality = nx.closeness_centrality(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Betweenness centrality\n",
    "# C(i) ~ # shortest paths between all pairs passing through node i\n",
    "# Very large span for large networks\n",
    "betweennessCentrality = nx.betweenness_centrality(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eigenvector centrality\n",
    "# The philosophy underneath this centrality measure: Important nodes are connected to important nodes\n",
    "# Eigen vector centrality is a recursive approach\n",
    "eigenvectorCentrality = nx.eigenvector_centrality(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Katz centrality\n",
    "katzCentrality = nx.katz_centrality(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Page Rank centrality\n",
    "pagerankCentrality = nx.pagerank(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2\n",
    "Compute the correlation between the introduced centrality measures over three datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Community and Homophily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The functions in this class are not imported into the top-level networkx namespace. You can access these functions by importing the networkx.algorithms.community module, then accessing the functions as attributes of community\n",
    "# This class implemented Newman-Girvan method\n",
    "# The other very popular community detection method is the Blondel method which is implemented in Gephi\n",
    "from networkx.algorithms import community\n",
    "communities_generator = community.girvan_newman(G)\n",
    "top_level_communities = next(communities_generator)\n",
    "next_level_communities = next(communities_generator)\n",
    "communities = sorted(map(sorted, next_level_communities))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Paths and geodesics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In calculating the shortest path between nodes in a graph, a very important point is to know whether the graph is connected or disconnected. If it's a connected graph there is no problem, otherwise in disconnected graph, the shortest path algorithm should applied on the connected components\n",
    "condition = nx.is_connected(G)\n",
    "sourceNode = \"1\"\n",
    "targetNode = \"30\"\n",
    "if condition:\n",
    "    print(nx.shortest_path_length(G, source=sourceNode, target=targetNode))\n",
    "    print(nx.shortest_path(G, source=sourceNode, target=targetNode))\n",
    "    print(list(nx.shortest_paths.all_shortest_paths(G, source=sourceNode, target=targetNode)))\n",
    "    # A simple path is a path with no repeated nodes\n",
    "    simplePaths = list(nx.simple_paths.all_simple_paths(G, source=sourceNode, target=targetNode))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we visualize the graph\n",
    "nx.draw(G, with_labels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.cycle_basis(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eulerian cycle\n",
    "# An Eulerian circuit is a path that crosses every edge in G exactly once and finishes at the starting node.\n",
    "EG = nx.Graph()\n",
    "EG.add_edges_from([(1,2),(1,3),(2,3)])\n",
    "if nx.is_eulerian(EG):\n",
    "    for a  in nx.eulerian_circuit(EG):\n",
    "        print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hamiltonian cycle\n",
    "HG = nx.DiGraph()\n",
    "HG.add_edges_from([(1,2),(2,3),(3,4),(4,1)])\n",
    "nx.tournament.hamiltonian_path(HG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe you noticed, the difference between hamiltonian and eulerian cycle is really small. An Euler path is a path that crosses every edge exactly once without repeating, if it ends at the initial vertex then it is Euler cycle. A Hamiltonian path passes through each vertex (note not each edge), exactly once, if it ends at the initial vertex then it is a Hamiltonian cycle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Bipartite networks and their projections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Erdos-Renyi random graphs - Scale Free Networks - Small World Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ERG = nx.erdos_renyi_graph(1000,0.2)\n",
    "SFN = nx.scale_free_graph(1000)\n",
    "SMW = nx.watts_strogatz_graph(1000,3,0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw three graphs degree distribution with different parameters. Can you see any pattern in their distribution? Also, compare their average path length, average degree and clustering coefficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epidemiology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epidemic processes are very important in both network science and its applications. The most common application is to study the was in which diseases progress in different network conditions, depending on their infectiousness and other properties. Typically such processes are modelled as a compartmented model of disease with conditional probabilities for moving between compartments (familiar to computer scientists as stochastic finite state machines)(from https://pythonhosted.org/epydemic/). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are quite a few compartmental models proposed by scholars. Among them we explore four models which are the most famous ones : SI, SIS, SIR and SEIR. Please note, networkx does not support epidemic modelling per se, and we need to install a new package called NDlib which is built on the top of networkx. For more information about this library please refer to http://ndlib.readthedocs.io/en/latest/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ndlib.models.ModelConfig as mc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SI Model\n",
    "# 0: Susceptible - 1: Infected\n",
    "# SI assumes that if, during a generic iteration, a susceptible node comes into contact with an infected one, it becomes infected with probability β: once a node becomes infected, it stays infected (the only transition allowed is S→I)\n",
    "# We set the initial set of infected nodes as 5% of the overall population and a probability of infection of 1%.\n",
    "\n",
    "import ndlib.models.epidemics.SIModel as si\n",
    "\n",
    "# Network topology\n",
    "g = nx.erdos_renyi_graph(1000, 0.1)\n",
    "\n",
    "# Model selection\n",
    "model = si.SIModel(g)\n",
    "\n",
    "# Model Configuration\n",
    "cfg = mc.Configuration()\n",
    "cfg.add_model_parameter('beta', 0.01)\n",
    "cfg.add_model_parameter(\"percentage_infected\", 0.05)\n",
    "model.set_initial_status(cfg)\n",
    "\n",
    "# Simulation execution\n",
    "iterations = model.iteration_bunch(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SIS Model\n",
    "# 0: Susceptible - 1: Infected\n",
    "# SIS assumes that if, during a generic iteration, a susceptible node comes into contact with an infected one, it becomes infected with probability beta, than it can be switch again to susceptible with probability lambda (the only transition allowed are S→I→S).\n",
    "# we set the initial set of infected nodes as 5% of the overall population, a probability of infection of 1%, and a probability of recovery of 0.5%.\n",
    "\n",
    "import ndlib.models.epidemics.SISModel as sis\n",
    "\n",
    "# Network topology\n",
    "g = nx.erdos_renyi_graph(1000, 0.1)\n",
    "\n",
    "# Model selection\n",
    "model = sis.SISModel(g)\n",
    "\n",
    "# Model Configuration\n",
    "cfg = mc.Configuration()\n",
    "cfg.add_model_parameter('beta', 0.01)\n",
    "cfg.add_model_parameter('lambda', 0.005)\n",
    "cfg.add_model_parameter(\"percentage_infected\", 0.05)\n",
    "model.set_initial_status(cfg)\n",
    "\n",
    "# Simulation execution\n",
    "iterations = model.iteration_bunch(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SIR Model\n",
    "# 0: Susceptible - 1: Infected - 2: Removed\n",
    "# SIR assumes that if, during a generic iteration, a susceptible node comes into contact with an infected one, it becomes infected with probability beta, than it can be switch to removed with probability gamma (the only transition allowed are S→I→R).\n",
    "# we set the initial set of infected nodes as 5% of the overall population, a probability of infection of 1%, and a removal probability of 0.5%.\n",
    "\n",
    "import ndlib.models.epidemics.SIRModel as sir\n",
    "\n",
    "# Network topology\n",
    "g = nx.erdos_renyi_graph(1000, 0.1)\n",
    "\n",
    "# Model selection\n",
    "model = sir.SIRModel(g)\n",
    "\n",
    "# Model Configuration\n",
    "cfg = mc.Configuration()\n",
    "cfg.add_model_parameter('beta', 0.01)\n",
    "cfg.add_model_parameter('gamma', 0.005)\n",
    "cfg.add_model_parameter(\"percentage_infected\", 0.05)\n",
    "model.set_initial_status(cfg)\n",
    "\n",
    "# Simulation execution\n",
    "iterations = model.iteration_bunch(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SEIR Model\n",
    "# 0: Susceptible - 1: Infected - 2: Exposed - 3: Removed\n",
    "# SEIR assumes that if, during a generic iteration, a susceptible node comes into contact with an infected one, it becomes infected after an exposition period with probability beta, than it can switch to removed with probability gamma (the only transition allowed are S→E→I→R).\n",
    "# we set the initial set of infected nodes as % of the overall population, a probability of infection of 1%, a removal probability of 0.5% and an incubation period of 5% (e.g. 20 iterations)\n",
    "\n",
    "import ndlib.models.epidemics.SEIRModel as seir\n",
    "\n",
    "# Network topology\n",
    "g = nx.erdos_renyi_graph(1000, 0.1)\n",
    "\n",
    "# Model selection\n",
    "model = seir.SEIRModel(g)\n",
    "\n",
    "# Model Configuration\n",
    "cfg = mc.Configuration()\n",
    "cfg.add_model_parameter('beta', 0.01)\n",
    "cfg.add_model_parameter('gamma', 0.005)\n",
    "cfg.add_model_parameter('alpha', 0.05)\n",
    "cfg.add_model_parameter(\"percentage_infected\", 0.05)\n",
    "model.set_initial_status(cfg)\n",
    "\n",
    "# Simulation execution\n",
    "iterations = model.iteration_bunch(200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bipartite Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx.algorithms import bipartite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = nx.Graph()\n",
    "# Add nodes with the node attribute \"bipartite\"\n",
    "B.add_nodes_from([1, 2, 3, 4], bipartite=0)\n",
    "B.add_nodes_from(['a', 'b', 'c'], bipartite=1)\n",
    "B.add_edges_from([(1, 'a'), (1, 'b'), (2, 'b'), (2, 'c'), (3, 'c'), (4, 'a')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(B, with_labels=True, pos=nx.fruchterman_reingold_layout(B))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom_nodes, top_nodes = bipartite.sets(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configuration Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BN = nx.bipartite.random_graph(3,4, 0.15)\n",
    "BN = nx.bipartite.configuration_model([2,3,4,5],[4,5,1,4])\n",
    "nx.draw(BN)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assortivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Robustness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Easy experiment for checking the robustness of the network\n",
    "\n",
    "#Edge removal\n",
    "TG1 = nx.generators.erdos_renyi_graph(50,0.2)\n",
    "for i in range(200):\n",
    "    edges = list(TG1.edges())\n",
    "    index = random.randint(0,len(edges)-1)\n",
    "#     print(index, len(edges))\n",
    "    TG1.remove_edge(edges[index][0],edges[index][1])\n",
    "    print(len(edges), nx.is_connected(TG1))\n",
    "    \n",
    "#Node removal\n",
    "TG2 = nx.generators.erdos_renyi_graph(50,0.1)\n",
    "for i in range(40):\n",
    "    nodes = list(TG2.nodes())\n",
    "    index = random.randint(0, len(nodes))\n",
    "    TG2.remove_node(nodes[index])\n",
    "    print(len(nodes), nx.is_connected(TG2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cliques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(G, with_labels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppose we have afriendship graph, in this graph cliques are those subgraphs all the nodes know eacch other \n",
    "# In a clique with the size of n, all the nodes have the degree of n-1\n",
    "# Further explanation: http://www.faculty.ucr.edu/~hanneman/nettext/C11_Cliques.html#subgraph\n",
    "# In networkx, finding the largest clique in a graph is NP-complete problem, so most of the algorithms have an exponential running time\n",
    "\n",
    "# The following function returns all the cliques (with different size) of a graph in an array \n",
    "allCliques = nx.enumerate_all_cliques(G)\n",
    "# list(allCliques)\n",
    "\n",
    "# The following function returns the clique number of the graph. The clique number of a graph is the size of the largest clique in the graph.\n",
    "cliqueNum = nx.graph_clique_number(G)\n",
    "# cliqueNum\n",
    "\n",
    "#The following function returns maximal clique of a graph. For each node v, a maximal clique for v is a largest complete subgraph containing v. The largest maximal clique is sometimes called the maximum clique.\n",
    "maximalCliques = nx.find_cliques(G)\n",
    "# list(maximalCliques)\n",
    "\n",
    "#The following function returns the number of maximal cliques in the graph.\n",
    "maximalCliquesNum = nx.graph_number_of_cliques(G)\n",
    "\n",
    "# The following function returns the number of maximal cliques for each node.\n",
    "nodeMaximalClique = nx.number_of_cliques(G)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the talk I had with Mason Porter (Oxford Mathematics Professor), dynamic network is a wrong term and instead of that we should replace it with temporal networks. In temporal networks both nodes and edges can change. New edges can appear, old edges can change(be remove or got bigger or smaller (in terms of weight)), new nodes appear, old nodes chages (be removed or got bigger or smaller)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To model temporal networks, we consider a time period and in each tick during this period we record the state of all elements. One of the best way to visualize temporal networks is Gephi but we need to give it the write input which has a special format. It is called gexf format. When we make a graph networkx can store it in this format, so to have a temporal networks, we create every snapshot of our network in networkx, then store that snapshot in gexf format. But still Gephi cannot identify the temporal dimension in the input and the created files need to be modified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### In the second line of each gexf file, there is this line of code:\n",
    "########### <graph defaultedgetype=\"undirected\" mode=\"static\" name=\"\">\n",
    "##### and it should be replaced with the following line:\n",
    "########### <graph mode=\"slice\" defaultedgetype=\"directed\" timerepresentation=\"timestamp\" timestamp=\"2016\">\n",
    "##### The timestamp and edgetype should change due to the case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Online Social Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are quite a few online social networks outside; however, we decided to work with Twitter network becasue (i) Despite its limitation (collecting data only from past seven days and getting only 1% of available data), Twitter is one of the few social networks that allows data collection, (ii) also, it's one of the most dynamic social networks which almost every social, political and economic topic will be reflected in it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to get data from Twitter, first you need to make a developer account. To do that you have to go this website https://apps.twitter.com/ and create an application (filling the form and explaining for what application you need to get Twitter API). After filling the form, go the the \"Keys and Access Tokesn\" and take four following codes: API Key, API Secret, Access Token, Access Token Secret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_Key = \"\"\n",
    "API_Secret = \"\"\n",
    "Access_Token = \"\"\n",
    "Access_Token_Secret =\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Twitter has two kind of API: (i) Search API which allows you to get access to historical data (not older than past 7 days), and (ii) Stream API which allows you to get access to the data that are currently comming to the Twitter. Here, we work with first type type of Twitter API, for working with second type of API, please refer to the files that comes with this notebook.\n",
    "Also, for getting further information about these two kinds of API, please refer to http://140dev.com/twitter-api-programming-tutorials/aggregating-tweets-search-api-vs-streaming-api/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can directly use Twitter API with HTTP request and related libraries in different programming languages, but becasue it is a fairly hard task and needs lots of efforts, programmers started writing something called Wrapper, which makes connection to the APIs very easy. For Twitter, there are quite a few wrapper in various programming languages. For Python two of the most popular APIs are Tweepy and Twython. Here, we used Tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "\n",
    "# Connecting to Twitter\n",
    "auth = tweepy.auth.OAuthHandler(API_Key, API_Secret)\n",
    "auth.set_access_token(Access_Token, Access_Token_Secret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweetObject = api.get_status(tweet.split(\"\\t\")[1], tweet_mode=\"extended\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "results = api.search(\"Trump\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_tweets = api.home_timeline()\n",
    "for tweet in public_tweets:\n",
    "    print(tweet.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
